#!/usr/bin/env python3

"""Usage:   tester (hr|lr) --input=input --output=output --model=model --architecture=arch [--lognorm] [--active]
            tester --help | -help | -h

Process input to create super resolution using the model input and plot it.
Arguments:
  input         a directory with input files
  output        a directory for saving the output images
  model         a .pt file to use for the model
  architecture  architecture to use: unet or axial
  --lognorm     If we want to use log normalization
  --active      Whether to save per-image metrics for active learning selection
Options:
  -h --help -h
"""
import os
from pathlib import Path

import torch

from dataset import SrDataset
from docopt import docopt

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from skimage import metrics
from unet import UNET
from axial_bicubic import AxialNet
from edsr import EDSR
from tqdm import tqdm

from PIL import Image, ImageFont, ImageDraw

def writetext(imgfile, e_sr, e_lr):
    img = Image.open(imgfile)
    width, height = img.size
    draw = ImageDraw.Draw(img)
    font = ImageFont.truetype('./font/dancing.ttf', 15) 
    draw.text((width/2, 0), "HR", font=font)
    draw.text((0, width/2), "Error", font=font)

    draw.text((0, 0), "SR", font=font)
    draw.text((32, 0), "L1="+str(e_sr[0]), font=font, fill=(255, 0, 0))
    draw.text((32, 16), "PSNR="+str(e_sr[1]), font=font, fill=(255, 0, 0))
    draw.text((32, 32), "SSIM="+str(e_sr[2]), font=font, fill=(255, 0, 0))

    draw.text((height/2, width/2), "LR", font=font, fill=(255, 255, 255))
    draw.text((height/2 + 32, width/2), "L1="+str(e_lr[0]),
              font=font, fill=(255, 0, 0))
    draw.text((height/2 + 32, width/2 + 16), "PSNR="+str(e_lr[1]),
              font=font, fill=(255, 0, 0))
    draw.text((height/2 + 32, width/2 + 32), "SSIM="+str(e_lr[2]),
              font=font, fill=(255, 0, 0))
    img.save("/tmp/test.png")
    os.system("mv /tmp/test.png " + imgfile)

def evaluate(args):
    """

    Parameters
    ----------
    args: the docopt arguments passed

    Returns
    -------

    """
    parameters = {"batch_size": 1, "shuffle": False, "num_workers": 6}
    use_cuda = torch.cuda.is_available()
    lognorm = args["--lognorm"]
    active_learning = args["--active"]
    device = torch.device("cuda:0" if use_cuda else "cpu")
    torch.backends.cudnn.benchmark = True

    test_set = SrDataset(args["--input"], lognorm=args["--lognorm"], test=True, hr=True)
    test_generator = torch.utils.data.DataLoader(test_set, **parameters)

    # model create and load
    if args["--architecture"] == 'unet':
        model = UNET(in_channels=1, out_channels=1, init_features=32)
    elif args["--architecture"] == 'axial':
        model = AxialNet(num_channels=1, resblocks=2, skip=1)
    elif  args["--architecture"] == 'edsr':
        model = EDSR(n_resblocks=16, n_feats=64, scale=1)

    model.to(device)
    test_loss = 0
    messed_images = 0
    test_psnr = 0.0
    test_ssim = 0.0
    lr_tot_psnr = 0.0
    lr_tot_ssim = 0.0
    model.load_state_dict(torch.load(args["--model"]))
    active_list = []
    with torch.no_grad():
        for batch_idx, data in tqdm(enumerate(test_generator), total = len(test_set.datalist)):
            model.eval()
            # unet.train(False)
            x_test = data["lr"]
            y_test = data["hr"]
            stat_test = data["stats"]
            x_test = x_test.to(device)
            y_test = y_test.numpy()
            y_pred = model(x_test)

            # Inverse of the nomalizations used. Applied on SR data
            stat_test["std"] = stat_test["std"].numpy()
            stat_test["mean"] = stat_test["mean"].numpy()
            y_pred = y_pred.cpu().numpy()
            y_pred = (y_pred * stat_test["std"]) + stat_test["mean"]
            y_pred =  np.clip(y_pred, stat_test["min"].numpy(), stat_test["max"].numpy())
            if lognorm:
                image_sign = np.sign(y_pred)
                y_pred = image_sign * (np.exp(np.abs(y_pred)) - 1.0)

            # Compute the loss if HR is given
            if args["hr"]:
                loss_test = np.mean(np.abs(y_pred - y_test))
                # loss_test = loss_test / stat_test["std"]
                if not active_learning:
                    sr_hr = np.hstack([y_pred.reshape(-1, y_pred.shape[-1]),
                                       y_test.reshape(-1, y_pred.shape[-1])])

            # Inverse normalize the LR image
            x_test = x_test.cpu().numpy()
            x_test = (x_test * stat_test["std"]) + stat_test["mean"]
            if lognorm:
                image_sign = np.sign(x_test)
                x_test = image_sign * (np.exp(np.abs(x_test)) - 1.0)

            # Create and save image consisting of error map, HR, SR, LR
            if not active_learning:
                if args["hr"]:
                    error = np.abs(y_pred - y_test).reshape(-1, y_pred.shape[-1])
                    error = error * (stat_test["max"].numpy() / np.max(error))
                    lr_error = np.hstack([error, x_test.reshape(-1, y_pred.shape[-1])])
                    save_plots = np.vstack([sr_hr, lr_error])
                else:
                    save_plots = np.vstack(
                        [y_pred.reshape(-1, y_pred.shape[-1]),
                         x_test.reshape(-1, y_pred.shape[-1])]
                    )
                filename = os.path.join(args["--output"], f"{batch_idx}.png")
                m = np.mean(save_plots)
                s = np.std(save_plots)
                plt.imsave(filename, save_plots, cmap="gray", vmin = stat_test["min"], vmax = m+3*s )
            if args["hr"]:
                test_loss = test_loss + loss_test
                lr_l1 = np.mean(np.abs(y_test - x_test))
                sr_l1 = np.mean(np.abs(y_test - y_pred))
                x_test = x_test.reshape(x_test.shape[3], -1)
                y_test = y_test.reshape(y_test.shape[3], -1)
                y_pred = y_pred.reshape(y_pred.shape[3], -1)
                lr_psnr = metrics.peak_signal_noise_ratio(y_test, x_test,
                                                          data_range=stat_test["max"].numpy())
                sr_psnr = metrics.peak_signal_noise_ratio(y_test, y_pred,
                                                          data_range=stat_test["max"].numpy())
                lr_ssim = metrics.structural_similarity(y_test, x_test,
                                                        gaussian_weights=True,
                                                        data_range=stat_test["max"].numpy())
                sr_ssim = metrics.structural_similarity(y_test, y_pred,
                                                        gaussian_weights=True,
                                                        data_range=stat_test["max"].numpy())
                test_psnr = test_psnr + sr_psnr[0]
                test_ssim = test_ssim + sr_ssim
                lr_tot_psnr = lr_tot_psnr + lr_psnr[0]
                lr_tot_ssim = lr_tot_ssim + lr_ssim
                srerror = (sr_l1, sr_psnr[0], sr_ssim)
                lrerror = (lr_l1, lr_psnr[0], lr_ssim)
                if not active_learning:
                    writetext(os.path.abspath(filename), srerror, lrerror)
                if sr_l1 > lr_l1:
                    messed_images = messed_images + 1
                if active_learning:
                    active_list.append([data["file"][0], sr_l1, sr_psnr[0],
                                        sr_ssim, lr_l1, lr_psnr[0], lr_ssim])

        if args["hr"]:
            print("\nTest Loss: {:.6f}".format(test_loss / len(test_generator)))
            print("\nTest PSNR: {:.6f}".format(test_psnr / len(test_generator)))
            print("\nTest SSIM: {:.6f}".format(test_ssim / len(test_generator)))
            print("\nLR PSNR: {:.6f}".format(lr_tot_psnr / len(test_generator)))
            print("\nLR SSIM: {:.6f}".format(lr_tot_ssim / len(test_generator)))
            print(f"NUmber of images where SR L1 is worse than LR: {messed_images}")
            if active_learning:
                df = pd.DataFrame(active_list, columns=['filename', 'SR_L1', 'SR_PSNR',
                                                   'SR_SSIM', 'LR_L1', 'LR_PSNR', 'LR_SSIM'])
                df.to_csv("active_metrics.csv")

if __name__ == "__main__":
    args = docopt(__doc__)
    for a in ["--input", "--output", "--model"]:
        args[a] = Path(args[a]).resolve()
    print("Input being read from:", args["--input"])
    #print(args)
    evaluate(args)
    """ An example:
     ./tester hr --input input.npz --output output.npz --model srunet.pt
    {'--help': False,
     '--input': True,
     '--model': True,
     '--output': True,
     '-e': False,
     '-l': False,
     '-p': False,
     'input': 'input_dir',
     'model': 'srunet.pt',
     'output': 'output_dir',
     'architecture': 'arch',
     'hr': True,
     'lr': False}
    """
